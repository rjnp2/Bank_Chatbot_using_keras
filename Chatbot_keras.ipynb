{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chatbot_keras.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBTk9hRzC6Cm"
      },
      "source": [
        "#### What is a Chatbot?\n",
        "A chatbot is an AI-based software designed to interact with humans in their natural languages. These chatbots are usually converse via auditory or textual methods, and they can effortlessly mimic human languages to communicate with human beings in a human-like manner. A chatbot is arguably one of the best applications of natural language processing.\n",
        "\n",
        "Chatbots can be categorized into two primary variants – Rule-Based and Self-learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dEn93dWC_B1"
      },
      "source": [
        "#### Rule-Based Conversational Chatbot\n",
        "The Rule-based approach trains a chatbot to answer questions based on a set of pre-determined rules on which it was initially trained. These set rules can either be very simple or very complex. While rule-based chatbots can handle simple queries quite well, they usually fail to process more complicated queries/requests.\n",
        "\n",
        "#### Self-Learning Chatbots\n",
        "\n",
        "self-learning bots are chatbots that can learn on their own. These leverage advanced technologies like Artificial Intelligence and Machine Learning to train themselves from instances and behaviours. Naturally, these chatbots are much smarter than rule-based bots. \n",
        "\n",
        "Self-learning bots can be further divided into two categories – **Retrieval Based and Generative.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4fTK41RDLZT"
      },
      "source": [
        "### 1. Retrieval-based Chatbots\n",
        "\n",
        "A retrieval-based chatbot is one that functions on predefined input patterns and set responses. Once the question/pattern is entered, the chatbot uses a heuristic approach to deliver the appropriate response. The retrieval-based model is extensively used to design goal-oriented chatbots with customized features like the flow and tone of the bot to enhance the customer experience.\n",
        "\n",
        "Retrieval based bots work on the principle of directed flows or graphs.The bot is trained to rank the best response from a finite set of predefined responses. The responses here are entered manually, or based on a knowledge base of pre-existing information.\n",
        "\n",
        "Eg. What are your store timings?\n",
        "Answer: 9 to 5 pm\n",
        "\n",
        "These systems can be extended to integrate with 3rd Party systems as well.\n",
        "\n",
        "Eg. Where is my order?\n",
        "Answer: It’s on its way and should reach you in 10 mins\n",
        "\n",
        "Retrieval based bots are the most common types of chatbots that you see today. They allow bot developers and UX to control the experience and match it to the expectations of our customers. They work best for goal-oriented bots in customer support, lead generation and feedback. We can decide the tone of the bot, and design the experience, keeping in mind the customer’s brand and reputation.\n",
        "\n",
        "### 2. Generative Chatbots\n",
        "Unlike retrieval-based chatbots, generative chatbots are not based on predefined responses – they leverage seq2seq neural networks. This is based on the concept of machine translation where the source code is translated from one language to another language. In seq2seq approach, the input is transformed into an output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_tAh-C8DYZk"
      },
      "source": [
        "### How To Make A Chatbot In Python?\n",
        "\n",
        "To build a chatbot in Python, we have to import all the necessary packages and initialize the variables to use in your chatbot project. Also, remember that when working with text data, we need to perform data preprocessing on we dataset before designing an ML model.\n",
        "\n",
        "This is where tokenizing helps with text data – it helps fragment the large text dataset into smaller, readable chunks (like words). Once that is done, we can also go for lemmatization that transforms a word into its lemma form. Then it creates a pickle file to store the python objects that are used for predicting the responses of the bot. \n",
        "\n",
        "Another vital part of the chatbot development process is creating the training and testing datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7sgFxPzDOOM"
      },
      "source": [
        "### Retrieval-based Chatbot building with help of Natural Language Processing(NLP) using NLTK and Deep Learning.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SQHZ5Jqnm2q",
        "outputId": "214f3eb3-194f-481c-aa50-040187188d3a"
      },
      "source": [
        "# Libraries needed for NLP\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Libraries needed for Tensorflow processing\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import random\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "7JnXKVLFnxRy",
        "outputId": "f3fe7741-e5b4-4cd5-c599-d7146ea2a1b9"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "# import our chat-bot intents file\n",
        "with open('intents.json') as json_data:\n",
        "    intents = json.load(json_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8e26e257-b19b-457f-a5d5-dc73b680d048\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8e26e257-b19b-457f-a5d5-dc73b680d048\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving intents.json to intents.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dsb2V2en23q",
        "outputId": "9f12a127-4640-4984-a24a-79352378fbad"
      },
      "source": [
        "words = []\n",
        "classes = []\n",
        "documents = []\n",
        "ignore = ['?',\"'s\",'!','.']\n",
        "# loop through each sentence in the intent's patterns\n",
        "for intent in intents['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "        # tokenize each and every word in the sentence\n",
        "        w = nltk.word_tokenize(pattern)\n",
        "        # add word to the words list\n",
        "        words.extend(w)\n",
        "        # add word(s) to documents\n",
        "        documents.append((w, intent['tag']))\n",
        "        # add tags to our classes list\n",
        "        if intent['tag'] not in classes:\n",
        "            classes.append(intent['tag'])\n",
        "\n",
        "# Perform lemmation and lower each word as well as remove duplicates\n",
        "words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore]\n",
        "words = sorted(list(set(words)))\n",
        "\n",
        "# remove duplicate classes\n",
        "classes = sorted(list(set(classes)))\n",
        "\n",
        "print (len(documents), \"documents\")\n",
        "print (len(classes), \"classes\", classes)\n",
        "print (len(words), \"unique stemmed words\", words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "73 documents\n",
            "15 classes ['CertificateofDeposits', 'CheckingAccount', 'MoneyMarketAccount', 'SavingAccount', 'accounts', 'accountstype', 'fun', 'goodbye', 'greeting', 'hours', 'location', 'noanswer', 'operateoption', 'options', 'thanks']\n",
            "85 unique stemmed words ['123', '555', 'a', 'account', 'address', 'again', 'an', 'anyone', 'are', 'bank', 'be', 'bye', 'byeee', 'can', 'certificate', 'checking', 'close', 'could', 'current', 'day', 'deposit', 'different', 'do', 'ffff', 'go', 'good', 'goodbye', 'hello', 'help', 'helpful', 'hey', 'hi', 'hour', 'how', 'i', 'in', 'individual', 'infomation', 'interest', 'is', 'it', 'later', 'located', 'location', 'market', 'me', 'meant', 'meet', 'money', 'new', 'nice', 'nnnn', 'of', 'offered', 'open', 'operate', 'operating', 'provide', 'rate', 'real', 'really', 'restaurant', 's', 'saving', 'see', 'situated', 'sup', 'support', 'thank', 'thanks', 'that', 'the', 'there', 'to', 'type', 'u', 'up', 'way', 'what', 'when', 'where', 'will', 'yo', 'you', 'your']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HKhNotxoJMX",
        "outputId": "44aa9546-aeff-4ae0-d74c-0c165a58d5a6"
      },
      "source": [
        "# create training data\n",
        "training = []\n",
        "output = []\n",
        "# create an empty array for output\n",
        "output_empty = [0] * len(classes)\n",
        "\n",
        "# create training set, bag of words for each sentence\n",
        "for doc in documents:\n",
        "    # initialize bag of words\n",
        "    bag = []\n",
        "    # list of tokenized words for the pattern\n",
        "    pattern_words = doc[0]\n",
        "    # stemming each word\n",
        "    pattern_words = [lemmatizer.lemmatize(w.lower()) for w in pattern_words]\n",
        "    # create bag of words array\n",
        "\n",
        "    for w in words:\n",
        "        bag.append(1) if w in pattern_words else bag.append(0)\n",
        "\n",
        "    # output is '1' for current tag and '0' for rest of other tags\n",
        "    output_row = list(output_empty)\n",
        "    output_row[classes.index(doc[1])] = 1\n",
        "\n",
        "    training.append([bag, output_row])\n",
        "\n",
        "# shuffling features and turning it into np.array\n",
        "random.shuffle(training)\n",
        "training = np.array(training)\n",
        "\n",
        "# creating training lists\n",
        "train_x = list(training[:,0])\n",
        "train_y = list(training[:,1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WO-klYCtokQm"
      },
      "source": [
        "# Create model - 3 layers. First layer 128 neurons, second layer 64 neurons and 3rd output layer contains number of neurons\n",
        "# equal to number of intents to predict output intent with softmax\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(len(train_y[0]), activation='softmax'))\n",
        "# Compile model. Stochastic gradient descent with Nesterov accelerated gradient gives good results for this model\n",
        "sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "#fitting and saving the model \n",
        "hist = model.fit(np.array(train_x), np.array(train_y), epochs=1000, batch_size=5, verbose=1)\n",
        "model.save('chatbot_model.h5', hist)\n",
        "print(\"model created\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A90Hx1S0rj22",
        "outputId": "887f4e6a-fac3-44de-f5b6-cf2f34b57303"
      },
      "source": [
        "print(hist.history['loss'][-1],hist.history['accuracy'][-1])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.046818431466817856 0.9863013625144958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Vp1Y4RAo7Ob"
      },
      "source": [
        "import pickle\n",
        "pickle.dump( {'words':words, 'classes':classes}, open( \"training_data\", \"wb\" ) )\n",
        "# restoring all the data structures\n",
        "data = pickle.load( open(\"training_data\", \"rb\"))\n",
        "words = data['words']\n",
        "classes = data['classes']\n",
        "\n",
        "with open('intents.json') as json_data:\n",
        "    intents = json.load(json_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGLI6utGpPPy"
      },
      "source": [
        "def clean_up_sentence(sentence):\n",
        "    # tokenizing the pattern\n",
        "    sentence_words = nltk.word_tokenize(sentence)\n",
        "    # stemming each word\n",
        "    sentence_words = [lemmatizer.lemmatize(w.lower()) for w in sentence_words]\n",
        "    return sentence_words\n",
        "\n",
        "# returning bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n",
        "def bow(sentence, words, show_details=False):\n",
        "    # tokenizing the pattern\n",
        "    sentence_words = clean_up_sentence(sentence)\n",
        "    # generating bag of words\n",
        "    bag = [0]*len(words)  \n",
        "\n",
        "    for s in sentence_words:\n",
        "        for i,w in enumerate(words):\n",
        "            if w == s: \n",
        "                bag[i] = 1\n",
        "                if show_details:\n",
        "                    print (\"found in bag: %s\" % w)\n",
        "\n",
        "    return(np.array(bag))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP-yFSw5pSmF"
      },
      "source": [
        "ERROR_THRESHOLD = 0.30\n",
        "from keras.models import load_model\n",
        "model = load_model('chatbot_model.h5')\n",
        "\n",
        "def classify(sentence):\n",
        "    # generate probabilities from the model\n",
        "    p = bow(sentence, words)\n",
        "    results = model.predict(np.array([p]))[0]\n",
        "    # filter out predictions below a threshold\n",
        "    results = [[i,r] for i,r in enumerate(results) if r>ERROR_THRESHOLD]\n",
        "    # sort by strength of probability\n",
        "    results.sort(key=lambda x: x[1], reverse=True)\n",
        "    return_list = []\n",
        "    for r in results:\n",
        "        return_list.append((classes[r[0]], r[1]))\n",
        "    # return tuple of intent and probability\n",
        "    return return_list\n",
        "\n",
        "def response(sentence, show_details=False):\n",
        "    results = classify(sentence)\n",
        "    # if we have a classification then find the matching intent tag\n",
        "    if results:\n",
        "        # loop as long as there are matches to process\n",
        "        while results:\n",
        "            for i in intents['intents']:\n",
        "                # find a tag matching the first result\n",
        "                if i['tag'] == results[0][0]:\n",
        "                    # a random response from the intent\n",
        "                    return random.choice(i['responses'])\n",
        "\n",
        "            results.pop(0)\n",
        "    else:\n",
        "       return \"Sorry, can't understand you\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLwaNZlxpYro",
        "outputId": "1155628f-8df6-4c5b-85d2-691ffae8718d"
      },
      "source": [
        "classify('What are you hours of operation?')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('hours', 0.98955965)]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2gfQm4cpcKn",
        "outputId": "f33fb954-7138-4b69-8d88-87fcc59c7049"
      },
      "source": [
        "classify(' ')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('noanswer', 0.9451791)]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XBN2u0zrprxC",
        "outputId": "e7af909e-725a-426f-a71f-5132ce948057"
      },
      "source": [
        "response('What are you hours of operation?')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"We're open every day 9am-4pm except friday 9am-2pm\""
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1XKjgugMptze",
        "outputId": "fa975c3f-4814-4c01-cc58-05d6bdd21a88"
      },
      "source": [
        "response(' ')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Sorry, can't understand you\""
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Z81DcEBpwJ-",
        "outputId": "2db84b58-a240-4e9e-bdab-f1b25505ceec"
      },
      "source": [
        "flag=True\n",
        "print(\"My name is Chatterbot and I'm a chatbot. If you want to exit, type Bye!\")\n",
        "\n",
        "while(flag==True):\n",
        "    user_response = input(\"You- \")\n",
        "    if(user_response not in ['bye','shutdown','exit', 'quit']):\n",
        "        if(user_response=='thanks' or user_response=='thank you' ):\n",
        "            flag=False\n",
        "            print(\"Chatterbot : You are welcome..\")\n",
        "        else:\n",
        "            answer = response(user_response)\n",
        "            print(answer)\n",
        "    else:\n",
        "        flag=False\n",
        "        print(\"Chatterbot : Bye!!! \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "My name is Chatterbot and I'm a chatbot. If you want to exit, type Bye!\n",
            "You- hi\n",
            "Hi there, how can I help?\n",
            "You- Are you real?\n",
            "I'm as real as you believe I'm\n",
            "You- real?\n",
            "I'm as real as you believe I'm\n",
            "You- ccss\n",
            "Sorry, can't understand you\n",
            "You-  help you provide\n",
            "I can guide you through Account, hours are we open, home delivery options\n",
            "You- What hours are you open?\n",
            "Our hours are 9am-4pm every day except friday 9am-2pm\n",
            "You- open?\n",
            "Our hours are 9am-4pm every day except friday 9am-2pm\n",
            "You- your location?\n",
            "We are on the intersection of London Alley and Bridge Avenue.\n",
            "You- accounts types in banks?\n",
            "The types of accounts are Checking Account, Saving Account, Money Market Account and CD (Certificate of Deposits) Account\n",
            "You- accounts types \n",
            "The types of accounts are Checking Account, Saving Account, Money Market Account and CD (Certificate of Deposits) Account\n",
            "You- accounts\n",
            "Saving Account: You can save your money in such account and also earn interest(5.05%) on it. The number of withdrawal is limited and need to maintain the minimum amount of balance in the account to remain active.\n",
            "You- accounts?\n",
            "Saving Account: You can save your money in such account and also earn interest(5.05%) on it. The number of withdrawal is limited and need to maintain the minimum amount of balance in the account to remain active.\n",
            "You- Checking Account?\n",
            "Checking Account: You can access the account as the saving account but, unlike saving account, you cannot earn interest on this account. The benefit of this account is that there is no limit for withdrawal.\n",
            "You- different ways to operate accounts?\n",
            "You can operate your bank accounts in different ways like a) Internet banking, b) Telephone or Mobile banking, c) Branch or Over the counter service, d) ATM(Automated Teller Machine)\n",
            "You- ways to operate accounts?\n",
            "You can operate your bank accounts in different ways like a) Internet banking, b) Telephone or Mobile banking, c) Branch or Over the counter service, d) ATM(Automated Teller Machine)\n",
            "You- operate accounts?\n",
            "You can operate your bank accounts in different ways like a) Internet banking, b) Telephone or Mobile banking, c) Branch or Over the counter service, d) ATM(Automated Teller Machine)\n",
            "You- bye\n",
            "Chatterbot : Bye!!! \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4E8Aregp6OR",
        "outputId": "57482378-98aa-4669-acf0-ac8d37c4d333"
      },
      "source": [
        "flag=True\n",
        "print(\"My name is Chatterbot and I'm a chatbot. If you want to exit, type Bye!\")\n",
        "\n",
        "while(flag==True):\n",
        "    user_response = input(\"You- \")\n",
        "    if(user_response not in ['bye','shutdown','exit', 'quit']):\n",
        "        if(user_response=='thanks' or user_response=='thank you' ):\n",
        "            flag=False\n",
        "            print(\"Chatterbot : You are welcome..\")\n",
        "        else:\n",
        "            answer = response(user_response)\n",
        "            print(answer)\n",
        "    else:\n",
        "        flag=False\n",
        "        print(\"Chatterbot : Bye!!! \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My name is Chatterbot and I'm a chatbot. If you want to exit, type Bye!\n",
            "Sorry, can't understand you\n",
            "Please give me more info\n",
            "Sorry, can't understand you\n",
            "Not sure I understand\n",
            "Not sure I understand\n",
            "Not sure I understand\n",
            "Saving Account: You can save your money in such account and also earn interest(5.05%) on it. The number of withdrawal is limited and need to maintain the minimum amount of balance in the account to remain active.\n",
            "Not sure I understand\n",
            "Please give me more info\n",
            "Please give me more info\n",
            "Sorry, can't understand you\n",
            "Not sure I understand\n",
            "Saving Account: You can save your money in such account and also earn interest(5.05%) on it. The number of withdrawal is limited and need to maintain the minimum amount of balance in the account to remain active.\n",
            "Saving Account: You can save your money in such account and also earn interest(5.05%) on it. The number of withdrawal is limited and need to maintain the minimum amount of balance in the account to remain active.\n",
            "Sorry, can't understand you\n",
            "Please give me more info\n",
            "Have a nice day\n",
            "I'm as real as you believe I'm\n",
            "I'm as real as you believe I'm\n",
            "You- bye\n",
            "Chatterbot : Bye!!! \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjAa9bWQuHWv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}